{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rizukaf-id/StyleMate-ML/blob/main/capstone%20(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b2122e59-93a2-4b1c-aa16-05a05b939bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2122e59-93a2-4b1c-aa16-05a05b939bdf",
        "outputId": "95a58f2f-875b-430d-d8ec-d3f1c1ddd8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHKZ4RFYm_ub",
        "outputId": "9601c4ba-3b1d-45e1-c686-2f7d7dd76b29"
      },
      "id": "FHKZ4RFYm_ub",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1673606a-9f0e-4083-8790-3c13edc0e5e6",
      "metadata": {
        "id": "1673606a-9f0e-4083-8790-3c13edc0e5e6"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import splitfolders\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "43b31ed9-a650-41e7-a5a8-637ff2f8cce8",
      "metadata": {
        "id": "43b31ed9-a650-41e7-a5a8-637ff2f8cce8"
      },
      "outputs": [],
      "source": [
        "# Extract the archive\n",
        "local_zip = '/content/drive/MyDrive/dataset_capstone/dataset_capstone/archive_2.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('data/')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a636645e-a933-4891-8b04-b47d006d662b",
      "metadata": {
        "id": "a636645e-a933-4891-8b04-b47d006d662b"
      },
      "outputs": [],
      "source": [
        "# base_dir = 'data/dataset_capstone/'\n",
        "# splitfolders.ratio(base_dir, output = 'data/dataset_capstone/dataset', seed = 1337, ratio=(0.8, 0.2), group_prefix=None)\n",
        "# train_dir = 'data/dataset_capstone/dataset/train'\n",
        "# val_dir = 'data/dataset_capstone/dataset/val'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/data/FaceShape Dataset/training_set'\n",
        "val_dir = '/content/data/FaceShape Dataset/testing_set'"
      ],
      "metadata": {
        "id": "IuH2Mp73rI1_"
      },
      "id": "IuH2Mp73rI1_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0275613d-3325-4084-8d22-9c08ca54f7ae",
      "metadata": {
        "id": "0275613d-3325-4084-8d22-9c08ca54f7ae"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "31c9510d-1a47-46f8-b308-c8547d17768f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31c9510d-1a47-46f8-b308-c8547d17768f",
        "outputId": "b86d7a7c-b7b9-49d9-da48-80167cafc959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 images belonging to 5 classes.\n",
            "Found 1000 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = training_datagen.flow_from_directory(\n",
        "\ttrain_dir,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=60\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tval_dir,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=60\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b00e5165-87dd-473e-af08-6d5f84310c92",
      "metadata": {
        "id": "b00e5165-87dd-473e-af08-6d5f84310c92"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.add(tf.keras.layers.BatchNormalization())"
      ],
      "metadata": {
        "id": "VTjYSSQBEt63"
      },
      "id": "VTjYSSQBEt63",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d78b7d8c-e8c2-4a81-93a6-8b8f4133d3a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d78b7d8c-e8c2-4a81-93a6-8b8f4133d3a4",
        "outputId": "0afdb598-74f0-4f33-9494-45745689becd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 148, 148, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPooli  (None, 74, 74, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 72, 72, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPooli  (None, 36, 36, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 17, 17, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 7, 7, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               6423040   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6833349 (26.07 MB)\n",
            "Trainable params: 6833349 (26.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4243b3d3-ec3a-43fa-b92a-315fa265f0f1",
      "metadata": {
        "id": "4243b3d3-ec3a-43fa-b92a-315fa265f0f1"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QUmouYyLFqr-"
      },
      "id": "QUmouYyLFqr-",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f4b59e2e-5a76-4953-827c-6aa3e5d3ea3c",
      "metadata": {
        "id": "f4b59e2e-5a76-4953-827c-6aa3e5d3ea3c"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "974964ab-a6ca-44db-b964-5b9e6af3730d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "974964ab-a6ca-44db-b964-5b9e6af3730d",
        "outputId": "504fdc03-79b6-41b4-fa9a-c4ebf0d36325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "67/67 [==============================] - 49s 715ms/step - loss: 1.6105 - accuracy: 0.1920 - val_loss: 1.6067 - val_accuracy: 0.2190\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 54s 801ms/step - loss: 1.6061 - accuracy: 0.2230 - val_loss: 1.6022 - val_accuracy: 0.2390\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 48s 720ms/step - loss: 1.5993 - accuracy: 0.2385 - val_loss: 1.5830 - val_accuracy: 0.2560\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 53s 800ms/step - loss: 1.5883 - accuracy: 0.2600 - val_loss: 1.5631 - val_accuracy: 0.2790\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 49s 731ms/step - loss: 1.5788 - accuracy: 0.2637 - val_loss: 1.6361 - val_accuracy: 0.2360\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 48s 719ms/step - loss: 1.5694 - accuracy: 0.2725 - val_loss: 1.5674 - val_accuracy: 0.2640\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 48s 721ms/step - loss: 1.5716 - accuracy: 0.2722 - val_loss: 1.5446 - val_accuracy: 0.3120\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 54s 804ms/step - loss: 1.5651 - accuracy: 0.2840 - val_loss: 1.5621 - val_accuracy: 0.2870\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 48s 721ms/step - loss: 1.5659 - accuracy: 0.2797 - val_loss: 1.5239 - val_accuracy: 0.3210\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 48s 719ms/step - loss: 1.5598 - accuracy: 0.2900 - val_loss: 1.5442 - val_accuracy: 0.3040\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 49s 731ms/step - loss: 1.5631 - accuracy: 0.2900 - val_loss: 1.5308 - val_accuracy: 0.3370\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 49s 732ms/step - loss: 1.5556 - accuracy: 0.2975 - val_loss: 1.6339 - val_accuracy: 0.2410\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 51s 756ms/step - loss: 1.5537 - accuracy: 0.2982 - val_loss: 1.5256 - val_accuracy: 0.3140\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 49s 738ms/step - loss: 1.5512 - accuracy: 0.2985 - val_loss: 1.5383 - val_accuracy: 0.3230\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 49s 737ms/step - loss: 1.5470 - accuracy: 0.2962 - val_loss: 1.5245 - val_accuracy: 0.3190\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 54s 805ms/step - loss: 1.5487 - accuracy: 0.2970 - val_loss: 1.6342 - val_accuracy: 0.2860\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 49s 726ms/step - loss: 1.5480 - accuracy: 0.2980 - val_loss: 1.5891 - val_accuracy: 0.2750\n",
            "Epoch 18/50\n",
            "63/67 [===========================>..] - ETA: 2s - loss: 1.5450 - accuracy: 0.2952"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=50, validation_data = validation_generator, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8419b30d-6b22-4d47-a0e6-5a5b22fd3200",
      "metadata": {
        "id": "8419b30d-6b22-4d47-a0e6-5a5b22fd3200"
      },
      "outputs": [],
      "source": [
        "pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9854695-9591-47f6-bd71-4790fb816fac",
      "metadata": {
        "id": "a9854695-9591-47f6-bd71-4790fb816fac"
      },
      "outputs": [],
      "source": [
        "import tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81bc06ef-0d98-4193-9d3b-d70e8e719dd5",
      "metadata": {
        "id": "81bc06ef-0d98-4193-9d3b-d70e8e719dd5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "saved_model_path = \"./{}.h5\".format(int(time.time()))\n",
        "\n",
        "model.save(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a71fec1-cd9f-40f2-ad63-2a4b4187e796",
      "metadata": {
        "id": "7a71fec1-cd9f-40f2-ad63-2a4b4187e796"
      },
      "outputs": [],
      "source": [
        "!tensorflowjs_converter --input_format=keras {saved_model_path} ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc04979b-17d6-42aa-a95e-b089b8050be3",
      "metadata": {
        "id": "dc04979b-17d6-42aa-a95e-b089b8050be3"
      },
      "outputs": [],
      "source": [
        "saved_model_path = \"./{}.h5\".format(int(time.time()))\n",
        "\n",
        "history.save(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7642f6d0-ad85-4bea-831c-341fbf06bc55",
      "metadata": {
        "id": "7642f6d0-ad85-4bea-831c-341fbf06bc55"
      },
      "outputs": [],
      "source": [
        "!tensorflowjs_converter --input_format=keras {saved_model_path} ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df7e8f27-46bb-414c-8740-6f7f7a750ad7",
      "metadata": {
        "id": "df7e8f27-46bb-414c-8740-6f7f7a750ad7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}